{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJTR1QSSWyqv"
   },
   "source": [
    "## Deep Neuroevolution Genetic Algorithm Approach to Super Mario Bros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version randomizes the world and stage order of the game while running each agent for multiple episodes each generation to specifically evolve for a better general Neural Mario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean check\n",
    "COLAB = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OHsgaN9asAZ"
   },
   "source": [
    "## Google Colab specific code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9yBB58IKXG9T",
    "outputId": "7e5d0757-8adc-479e-e40c-d4413af87673"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    !pip install gym-super-mario-bros\n",
    "    !mkdir Output\n",
    "    !mkdir .video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-g30xp8caS5U",
    "outputId": "21b78f3c-a75e-4860-956b-1decf3ebe580"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # Connect Google Drive\n",
    "    from google.colab import drive\n",
    "    #drive.mount('/content/gdrive')\n",
    "    drive.mount('/content/gdrive', force_remount=True)\n",
    "    print('Google Drive connected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WWXRgG2Yod2M"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # Copy over the fittest NeuralMario\n",
    "    !cp \"gdrive/MyDrive/SMB Genetic Random/Output/fittestMario.pkl\" -r \"Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fiRLsFmoeKVu"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # Create a virtual display for video rendering on the headless server.\n",
    "    !apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
    "    !pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(400, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWTdo-hxalUH"
   },
   "source": [
    "## Regular Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Km37L4U9WyrE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "from gym.wrappers import Monitor\n",
    "action_count = 7 # SIMPLE_MOVEMENT\n",
    "import cv2\n",
    "\n",
    "import multiprocessing\n",
    "from itertools import repeat\n",
    "\n",
    "from mutate import mutate\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlgjaNZ7WyrI"
   },
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9OSSOe4OWyrM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Model Definitions\\nclass Flatten(torch.nn.Module):\\n    def forward(self, x):\\n        return x.view(x.size()[0], -1)\\n\\nclass NeuralMario(nn.Module):\\n        def __init__(self, action_count):\\n            super().__init__()\\n            self.cuda()\\n            self.fc = nn.Sequential(\\n                        nn.Conv2d(4, 8, 3, bias=True),\\n                        nn.ReLU(inplace=True),\\n                        nn.Conv2d(8, 6, 3, bias=True),\\n                        nn.ReLU(inplace=True),\\n                        Flatten(),\\n                        nn.Linear(4704, 32, bias=True),\\n                        nn.ReLU(inplace=True),\\n                        nn.Linear(32, action_count, bias=True),\\n                        nn.Softmax(dim=1)\\n                        )\\n\\n\\n        def forward(self, inputs):\\n            x = self.fc(inputs)\\n            return x\\n\\ndef init_weights(m):\\n\\n        # nn.Conv2d weights are of shape [16, 1, 3, 3] i.e. # number of filters, 1, stride, stride\\n        # nn.Conv2d bias is of shape [16] i.e. # number of filters\\n\\n        # nn.Linear weights are of shape [32, 24336] i.e. # number of input features, number of output features\\n        # nn.Linear bias is of shape [32] i.e. # number of output features\\n\\n        if ((type(m) == nn.Linear) | (type(m) == nn.Conv2d)):\\n            torch.nn.init.xavier_uniform(m.weight)\\n            m.bias.data.fill_(0.00)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Model Definitions\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)\n",
    "\n",
    "class NeuralMario(nn.Module):\n",
    "        def __init__(self, action_count):\n",
    "            super().__init__()\n",
    "            self.cuda()\n",
    "            self.fc = nn.Sequential(\n",
    "                        nn.Conv2d(4, 8, 3, bias=True),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(8, 6, 3, bias=True),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        Flatten(),\n",
    "                        nn.Linear(4704, 32, bias=True),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Linear(32, action_count, bias=True),\n",
    "                        nn.Softmax(dim=1)\n",
    "                        )\n",
    "\n",
    "\n",
    "        def forward(self, inputs):\n",
    "            x = self.fc(inputs)\n",
    "            return x\n",
    "\n",
    "def init_weights(m):\n",
    "\n",
    "        # nn.Conv2d weights are of shape [16, 1, 3, 3] i.e. # number of filters, 1, stride, stride\n",
    "        # nn.Conv2d bias is of shape [16] i.e. # number of filters\n",
    "\n",
    "        # nn.Linear weights are of shape [32, 24336] i.e. # number of input features, number of output features\n",
    "        # nn.Linear bias is of shape [32] i.e. # number of output features\n",
    "\n",
    "        if ((type(m) == nn.Linear) | (type(m) == nn.Conv2d)):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.00)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB1zK08TWyrO"
   },
   "source": [
    "### Environment Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Rb7CO1GFWyrR"
   },
   "outputs": [],
   "source": [
    "# Environment Handling\n",
    "def convert_image(input_image):\n",
    "    image = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)\n",
    "    return cv2.resize(image, (32,32))\n",
    "\n",
    "def run_agent(agent, worlds, stages, agent_num, num_agents, rendering=False, monitoring=False, print_reward=False, episodes=2):\n",
    "    \n",
    "    global_reward = 0\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        episode_reward = 0\n",
    "        \n",
    "        y = str(worlds[i])\n",
    "        z = str(stages[i])\n",
    "        env = gym_super_mario_bros.make(\"SuperMarioBros-\" + y + \"-\" + z + \"-v0\")\n",
    "        \n",
    "        env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "\n",
    "        if monitoring:\n",
    "            env = Monitor(env, './video', force=True)\n",
    "\n",
    "        env.seed(42)\n",
    "\n",
    "        agent.eval()\n",
    "        \n",
    "        state = env.reset()\n",
    "        if rendering:\n",
    "            env.render()\n",
    "\n",
    "        #Conv2d without flatten()\n",
    "        state = convert_image(state)#.flatten()\n",
    "        state_list = [state, state, state, state]\n",
    "        position = -1\n",
    "\n",
    "        s=0\n",
    "        \n",
    "        while True:\n",
    "            #Conv2d input\n",
    "            input = torch.from_numpy(np.array(state_list)).type('torch.FloatTensor')\\\n",
    "                .unsqueeze(0)\n",
    "\n",
    "            #Linear input\n",
    "            #input = torch.tensor(state_list).type(\"torch.FloatTensor\").view(1,-1)\n",
    "\n",
    "            output_probabilities = agent(input).detach().numpy()[0]\n",
    "            action = np.random.choice(range(action_count), 1, \\\n",
    "                p=output_probabilities).item()\n",
    "            try:\n",
    "                new_state, reward, done, info = env.step(action)\n",
    "            except:\n",
    "                break\n",
    "            episode_reward += reward\n",
    "\n",
    "            s=s+1\n",
    "            if rendering:\n",
    "                env.render()\n",
    "\n",
    "            state_list.pop()\n",
    "            #Conv2d without flatten()\n",
    "            state_list.append(convert_image(new_state))#.flatten())\n",
    "\n",
    "            # if mario gets stuck, it gets punished and the loop gets broken\n",
    "            if position == info[\"x_pos\"]:\n",
    "                stuck += 1\n",
    "                if stuck == 100:\n",
    "                    episode_reward -= 100\n",
    "                    break\n",
    "            else:\n",
    "                stuck = 0\n",
    "\n",
    "            position = info[\"x_pos\"]\n",
    "            #env.render()\n",
    "            #Mario died\n",
    "            if info[\"life\"] < 2:\n",
    "                break\n",
    "                \n",
    "        print(\"Agent: \" + str(agent_num+1) + \"/\" + str(num_agents) +\\\n",
    "              \"\\tEpisode: \" + str(i+1) + \"/\" + str(episodes) + \"\\tReward: \"\\\n",
    "              + str(episode_reward) + \"\\t\", end = '\\r')\n",
    "        \n",
    "        global_reward += episode_reward\n",
    "    \n",
    "    mean_reward = global_reward / episodes\n",
    "    \n",
    "    if print_reward:\n",
    "        print(\"Total:\" + str(global_reward) + \"\\tMean: \" + str(mean_reward))\n",
    "\n",
    "    return mean_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agents_n_times(agents, runs, random=True):\n",
    "    avg_score = []\n",
    "    worlds = []\n",
    "    stages = []\n",
    "    num_agents = len(agents)\n",
    "    \n",
    "    if random:\n",
    "        for i in range(runs):\n",
    "            worlds.append(np.random.randint(1, 9))\n",
    "            stages.append(np.random.randint(1, 5))\n",
    "    else:\n",
    "        for i in range(8):\n",
    "            for j in range(4):\n",
    "                worlds.append(i+1)\n",
    "                stages.append(j+1)\n",
    "        \n",
    "    for i, agent in enumerate(agents):\n",
    "        avg_score.append(run_agent(agent, episodes=runs, worlds=worlds, stages=stages, agent_num=i, num_agents=num_agents))\n",
    "        \n",
    "    return avg_score\n",
    "\n",
    "\n",
    "def return_random_agents(num_agents):\n",
    "    agents = []\n",
    "    for _ in range(num_agents):\n",
    "\n",
    "        agent = NeuralMario(action_count)\n",
    "\n",
    "        for param in agent.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        init_weights(agent)\n",
    "        agents.append(agent)\n",
    "\n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(agent, rendering=True, monitoring=True, print_reward=True):\n",
    "\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-v0\")\n",
    "    env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "\n",
    "    if monitoring:\n",
    "        env = Monitor(env, './video', force=True)\n",
    "\n",
    "    env.seed(42)\n",
    "\n",
    "    agent.eval()\n",
    "        \n",
    "    state = env.reset()\n",
    "    if rendering:\n",
    "        env.render()\n",
    "\n",
    "    #Conv2d without flatten()\n",
    "    state = convert_image(state)#.flatten()\n",
    "    state_list = [state, state, state, state]\n",
    "    position = -1\n",
    "    \n",
    "    global_reward = 0\n",
    "    s=0\n",
    "        \n",
    "    for _ in range(30000):\n",
    "        #Conv2d input\n",
    "        input = torch.from_numpy(np.array(state_list)).type('torch.FloatTensor')\\\n",
    "                .unsqueeze(0)\n",
    "\n",
    "        #Linear input\n",
    "        #input = torch.tensor(state_list).type(\"torch.FloatTensor\").view(1,-1)\n",
    "\n",
    "        output_probabilities = agent(input).detach().numpy()[0]\n",
    "        action = np.random.choice(range(action_count), 1, \\\n",
    "            p=output_probabilities).item()\n",
    "        try:\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "        except:\n",
    "            break\n",
    "        global_reward += reward\n",
    "\n",
    "        s=s+1\n",
    "        if rendering:\n",
    "            env.render()\n",
    "\n",
    "        state_list.pop()\n",
    "        #Conv2d without flatten()\n",
    "        state_list.append(convert_image(new_state))#.flatten())\n",
    "\n",
    "        # if mario gets stuck, it gets punished and the loop gets broken\n",
    "        if position == info[\"x_pos\"]:\n",
    "            stuck += 1\n",
    "            if stuck == 100:\n",
    "                global_reward -= 100\n",
    "                break\n",
    "        else:\n",
    "            stuck = 0\n",
    "\n",
    "        position = info[\"x_pos\"]\n",
    "        #env.render()\n",
    "        #Mario died\n",
    "        if info[\"life\"] < 2:\n",
    "            break\n",
    "\n",
    "    return global_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Mutate, as a worker function in this version, must be imported for Windows\\ndef mutate(agent, power=0.2, chance=0.02):\\n    # Simple method to add gaussian noise to the agents\\n\\n    child_agent = copy.deepcopy(agent)\\n    \\n    \"\"\"\\n    gpu = False\\n    if torch.cuda.is_available():\\n        gpu = True\\n        child_agent.to(\"cuda:0\")\\n    \"\"\"\\n\\n    mutation_power = power #hyper-parameter, 0.2 set from https://arxiv.org/pdf/1712.06567.pdf\\n    \\n    # Current checks for mutation: 33189\\n    mutation_chance = chance\\n    \\n    for param in child_agent.parameters():\\n        \\n        if(len(param.shape)==4): #weights of Conv2D\\n            for i0 in range(param.shape[0]):\\n                for i1 in range(param.shape[1]):\\n                    for i2 in range(param.shape[2]):\\n                        if np.random.random(1)[0] <= mutation_chance:\\n                            for i3 in range(param.shape[3]):\\n                                param[i0][i1][i2][i3]+= mutation_power * np.random.randn()\\n                        else:\\n                            pass\\n\\n        elif(len(param.shape)==2): #weights of linear layer\\n            for i0 in range(param.shape[0]):\\n                for i1 in range(param.shape[1]):\\n                    if np.random.random(1)[0] <= mutation_chance:\\n                        param[i0][i1]+= mutation_power * np.random.randn()\\n                    else:\\n                        pass\\n\\n        elif(len(param.shape)==1): #biases of linear layer or conv layer\\n            for i0 in range(param.shape[0]):\\n                if np.random.random(1)[0] <= mutation_chance:\\n                    param[i0]+=mutation_power * np.random.randn()\\n                else:\\n                    pass\\n    \\n    \"\"\"\\n    if gpu:\\n        child_agent.to(\"cpu\")\\n    \"\"\"\\n    \\n    return child_agent\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Mutate, as a worker function in this version, must be imported for Windows\n",
    "def mutate(agent, power=0.2, chance=0.02):\n",
    "    # Simple method to add gaussian noise to the agents\n",
    "\n",
    "    child_agent = copy.deepcopy(agent)\n",
    "    \n",
    "    \"\"\"\n",
    "    gpu = False\n",
    "    if torch.cuda.is_available():\n",
    "        gpu = True\n",
    "        child_agent.to(\"cuda:0\")\n",
    "    \"\"\"\n",
    "\n",
    "    mutation_power = power #hyper-parameter, 0.2 set from https://arxiv.org/pdf/1712.06567.pdf\n",
    "    \n",
    "    # Current checks for mutation: 33189\n",
    "    mutation_chance = chance\n",
    "    \n",
    "    for param in child_agent.parameters():\n",
    "        \n",
    "        if(len(param.shape)==4): #weights of Conv2D\n",
    "            for i0 in range(param.shape[0]):\n",
    "                for i1 in range(param.shape[1]):\n",
    "                    for i2 in range(param.shape[2]):\n",
    "                        if np.random.random(1)[0] <= mutation_chance:\n",
    "                            for i3 in range(param.shape[3]):\n",
    "                                param[i0][i1][i2][i3]+= mutation_power * np.random.randn()\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "        elif(len(param.shape)==2): #weights of linear layer\n",
    "            for i0 in range(param.shape[0]):\n",
    "                for i1 in range(param.shape[1]):\n",
    "                    if np.random.random(1)[0] <= mutation_chance:\n",
    "                        param[i0][i1]+= mutation_power * np.random.randn()\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "        elif(len(param.shape)==1): #biases of linear layer or conv layer\n",
    "            for i0 in range(param.shape[0]):\n",
    "                if np.random.random(1)[0] <= mutation_chance:\n",
    "                    param[i0]+=mutation_power * np.random.randn()\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    \"\"\"\n",
    "    if gpu:\n",
    "        child_agent.to(\"cpu\")\n",
    "    \"\"\"\n",
    "    \n",
    "    return child_agent\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cIOYCiHdWyrU"
   },
   "outputs": [],
   "source": [
    "def return_children(agents, sorted_parent_indexes, elite_count, mutation_power, mutation_chance, multiprocess=False):\n",
    "    \"\"\" Returning [N-elite_count] mutated agents from sorted_parent_indexes and\n",
    "        keeping the best [elite_count] agents unchanged\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Mutating \" + str(elite_count) + \" elite agent(s) into the next generation.\", end='\\r')\n",
    "\n",
    "    if __name__ ==  '__main__': \n",
    "        if multiprocess:\n",
    "            print(\"Multiprocessing\")\n",
    "\n",
    "            iterable = zip(agents, repeat(mutation_power), repeat(mutation_chance))\n",
    "            with multiprocessing.Pool() as pool:\n",
    "                children_agents = pool.map(mutate(), iterable)\n",
    "            \n",
    "    else:\n",
    "        children_agents = []\n",
    "        for i in range(len(agents)-elite_count):\n",
    "            selected_agent_index = sorted_parent_indexes[np.random.randint(len(sorted_parent_indexes))]\n",
    "            children_agents.append(mutate(agents[selected_agent_index], mutation_power, mutation_chance))\n",
    "    \n",
    "    \n",
    "    elite_children = []\n",
    "    for i in range(elite_count):\n",
    "        elite_children.append(agents[sorted_parent_indexes[i]])\n",
    "\n",
    "    children_agents.extend(elite_children)\n",
    "\n",
    "    return children_agents\n",
    "\n",
    "def return_hot_start(elite_agent, num_agents, mutation_power, mutation_chance, multiprocess):\n",
    "    \"\"\" Mutate from a single saved elite agent, or fittestMario, in order to\n",
    "        start evolving a generation immediately without waiting for a single\n",
    "        generation of elite copies to process.\n",
    "        \n",
    "        Only recommended when only a single elite agent is preserved across\n",
    "        generations.\n",
    "    \"\"\"\n",
    "    if multiprocess:\n",
    "        print(\"Multiprocessing\")\n",
    "        \n",
    "        agents = []\n",
    "        \n",
    "        for i in range(num_agents-1):\n",
    "            agents.append(elite_agent)\n",
    "        \n",
    "        with multiprocessing.Pool() as pool:\n",
    "            iterable = zip(agents, repeat(mutation_power), repeat(mutation_chance))\n",
    "            children_agents = pool.map(mutate, iterable)\n",
    "            \n",
    "    else:\n",
    "        children_agents = []\n",
    "    \n",
    "        for i in range(num_agents-1):\n",
    "            children_agents.append(mutate(elite_agent, mutation_power, mutation_chance))\n",
    "\n",
    "    children_agents.extend([elite_agent])\n",
    "    \n",
    "    return children_agents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(elite_agent, mutation_power, mutation_chance, episodes, agents=10, elites=1, show_top=2, generations=100, hot_start=False, random=True, multiprocess=False):\n",
    "    torch.set_grad_enabled(False)\n",
    "    num_agents = agents\n",
    "    elite_count = elites\n",
    "    top_limit_count = show_top\n",
    "    n_episodes = episodes\n",
    "\n",
    "    generation_count = generations\n",
    "\n",
    "    if (elite_agent != None) and (not hot_start):\n",
    "        print(\"Loaded \" + str(num_agents) + \" elite copies.\")\n",
    "        agents = [elite_agent]*num_agents\n",
    "    elif (elite_agent != None) and hot_start:\n",
    "        print(\"Hot start enabled. Mutating loaded elite \" + str(num_agents-1) + \" times.\")\n",
    "        agents = return_hot_start(elite_agent, num_agents, mutation_power, mutation_chance, multiprocess)\n",
    "    elif (elite_agent == None) and hot_start:\n",
    "        print(\"Hot start enabled without required elite agent.\")\n",
    "        print(\"Creating \" + str(num_agents) + \" random agents.\")\n",
    "        agents = return_random_agents(num_agents)\n",
    "    else:\n",
    "        print(\"Creating \" + str(num_agents) + \" random agents.\")\n",
    "        agents = return_random_agents(num_agents)\n",
    "    \n",
    "    for generation in range(generation_count):\n",
    "        print(\"############## Generation {} ##############\".format(generation+1))\n",
    "        \n",
    "        rewards = run_agents_n_times(agents, n_episodes, random)\n",
    "\n",
    "        sorted_parent_indexes = np.argsort(rewards)[::-1][:top_limit_count]\n",
    "        \n",
    "        top_rewards = []\n",
    "        for best_parent in sorted_parent_indexes:\n",
    "            top_rewards.append(rewards[best_parent])\n",
    "\n",
    "        print(\"Mean reward: {}\\t\\t| Mean of top 5: {}\".format(\\\n",
    "            int(np.mean(rewards)), int(np.mean(top_rewards[:5]))))\n",
    "        print(\"Top agents: {}\\t| Reward: {}\".format(sorted_parent_indexes, \\\n",
    "            top_rewards))\n",
    "        print(\"###########################################\\n\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        \n",
    "        with open(\"Output/fittestMario.pkl\", 'wb') as output:\n",
    "            pickle.dump(agents[sorted_parent_indexes[0]], output, \\\n",
    "                pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        children_agents = return_children(agents, sorted_parent_indexes, elite_count, mutation_power, mutation_chance, multiprocess)\n",
    "\n",
    "        agents = children_agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAxnKa02WyrW"
   },
   "source": [
    "### Model Loading and Training\n",
    "The training function is defined here.\n",
    "Control Arguments:\n",
    "* <b>training:</b> If True, the genetic algorithm evolves the neural network(s), If False, the best agent is loaded and plays a game, with the gym monitor recording the video.\n",
    "\n",
    "* <b>load_elite:</b> If True, the previous elite agent is loaded from file. If False, all previous trainings are ignored and overwritten.\n",
    "\n",
    "* <b>agents:</b> The number of agents in the population.\n",
    "\n",
    "* <b>elites:</b> The number of elite agents to carry over across generations, and to mutate from.\n",
    "\n",
    "* <b>show_top:</b> The number of top agent rewards scores to display in the evolution output.\n",
    "\n",
    "* <b>generations:</b> The number of generations to create and test.\n",
    "\n",
    "* <b>mutation_power:</b> The Gaussian noise multiplier for the mutation function to use.\n",
    "\n",
    "* <b>mutation_chance:</b> The percentage chance for a genotype to undergo mutation within a generation creation.\n",
    "\n",
    "* <b>episodes:</b> The number of game runs to use when evaluating the performance of each agent within a generation.\n",
    "\n",
    "* <b>hot_start:</b> If True, create the first generation via mutations of the single loaded elite agent from a previous session. If False, either create a generation of completely random agents or make copies of the loaded elite agent if available. <b>Not recommended if implementing multiple-agent elitism.</b>\n",
    "\n",
    "* <b>random:</b> If True, randomly sample stages across all worlds for the evaluation of each agent each generation. If False, evaluate via every stage in the game sequentially.\n",
    "\n",
    "* <b>multiprocess:</b> If True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kwizQF_2WyrZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Training\n",
    "def train(training=True, load_elite=True, agents=10, elites=1, show_top=2, generations=100, mutation_power=0.2, mutation_chance=0.02, episodes=2, hot_start=False, random=True, multiprocess=False):\n",
    "    if training:\n",
    "        elite_agent = None\n",
    "        if load_elite:\n",
    "            with open(\"Output/fittestMario.pkl\", 'rb') as input:\n",
    "                elite_agent = pickle.load(input)\n",
    "        \n",
    "        # If not randomly sampling, all 32 stages are sequentially tested.\n",
    "        if not random:\n",
    "            print()\n",
    "            episodes = 32\n",
    "            \n",
    "        main(elite_agent, mutation_power, mutation_chance, episodes, agents, elites, show_top, generations, hot_start, random, multiprocess)\n",
    "\n",
    "    else:\n",
    "        with open(\"Output/fittestMario.pkl\", 'rb') as input:\n",
    "            fittest_mario = pickle.load(input)\n",
    "            test_agent(fittest_mario, True, True, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dIuiwpiWyra",
    "outputId": "bac618f1-935c-4fe6-9213-a6946f58c663",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'NeuralMario' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8a9545a090bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train, load, agents, elite, display top, generations, mutation_power, mutation_chance, episodes per generation, hot_start, randomize stages, multiprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-cced5a087c9e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(training, load_elite, agents, elites, show_top, generations, mutation_power, mutation_chance, episodes, hot_start, random, multiprocess)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload_elite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Output/fittestMario.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                 \u001b[0melite_agent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# If not randomly sampling, all 32 stages are sequentially tested.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'NeuralMario' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# train, load, agents, elite, display top, generations, mutation_power, mutation_chance, episodes per generation, hot_start, randomize stages, multiprocessing\n",
    "train(True, True, 100, 1, 5, 50, 0.2, 1.0, 32, True, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJaWpdt6qIA_"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    !cp \"Output\" -r \"gdrive/MyDrive/SMB Genetic Random/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUdfD-lMWyrf"
   },
   "source": [
    "This will now run the best neural network one more time, wrapped in the monitor environment to record video of play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSJQTjO6Wyrj"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    try:\n",
    "        display.start()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkyj0n_bbQnv"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    !cp \"video\" -r \"gdrive/MyDrive/SMB Genetic Random/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deep Neuroevolution SMB PreGPU Backup.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mario_dqn",
   "language": "python",
   "name": "mario_dqn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
